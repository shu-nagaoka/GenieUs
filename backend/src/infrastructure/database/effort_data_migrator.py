"""åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç§»è¡Œãƒ„ãƒ¼ãƒ«ï¼ˆJSON â†’ SQLiteï¼‰

ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„æº–æ‹ :
- Importæ–‡ãƒ•ã‚¡ã‚¤ãƒ«å…ˆé ­é…ç½®
- å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œå‚™
- DIæ³¨å…¥ãƒ‘ã‚¿ãƒ¼ãƒ³
- æ®µéšçš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any

from src.config.settings import AppSettings
from src.domain.entities import EffortReportRecord
from src.infrastructure.adapters.persistence.sqlite.effort_report_repository_sqlite import (
    EffortReportRepository as SQLiteEffortReportRepository,
)
from src.infrastructure.database.sqlite_manager import SQLiteManager


class EffortDataMigrator:
    """åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç§»è¡Œãƒ„ãƒ¼ãƒ«ï¼ˆJSON â†’ SQLiteï¼‰

    è²¬å‹™:
    - æ—¢å­˜JSONåŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆã®SQLiteãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    - ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ç¢ºä¿
    - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
    """

    def __init__(
        self,
        settings: AppSettings,
        sqlite_manager: SQLiteManager,
        logger: logging.Logger,
    ):
        """EffortDataMigratoråˆæœŸåŒ–

        Args:
            settings: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
            sqlite_manager: SQLiteãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
            logger: DIã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰æ³¨å…¥ã•ã‚Œã‚‹ãƒ­ã‚¬ãƒ¼
        """
        self.settings = settings
        self.sqlite_manager = sqlite_manager
        self.logger = logger
        self.effort_repository = SQLiteEffortReportRepository(sqlite_manager=sqlite_manager, logger=logger)

        # JSON ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        self.json_file_path = Path("data/effort_reports.json")
        self.backup_file_path = Path("data/effort_reports_backup.json")

    async def migrate_effort_data(self) -> dict[str, Any]:
        """åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’JSONã‹ã‚‰SQLiteã«ç§»è¡Œ

        Returns:
            dict[str, Any]: ç§»è¡Œçµæœçµ±è¨ˆ
        """
        try:
            self.logger.info("ğŸš€ åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç§»è¡Œé–‹å§‹")

            # ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–
            await self.effort_repository.initialize_table()

            # JSON ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            json_data = self._load_json_data()
            if not json_data:
                return {
                    "success": True,
                    "message": "ç§»è¡Œå¯¾è±¡ã®åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    "migrated_count": 0,
                    "failed_count": 0,
                }

            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            self._create_backup(json_data)

            # ç§»è¡Œå®Ÿè¡Œ
            migration_stats = await self._migrate_data(json_data)

            # æ¤œè¨¼
            await self._verify_migration(migration_stats["migrated_count"])

            self.logger.info(f"âœ… åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç§»è¡Œå®Œäº†: {migration_stats}")
            return migration_stats

        except Exception as e:
            self.logger.error(f"âŒ åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "migrated_count": 0,
                "failed_count": 0,
            }

    def _load_json_data(self) -> dict[str, Any] | None:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

        Returns:
            dict[str, Any] | None: JSONãƒ‡ãƒ¼ã‚¿ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneï¼‰
        """
        try:
            if not self.json_file_path.exists():
                self.logger.info(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {self.json_file_path}")
                return None

            with open(self.json_file_path, encoding="utf-8") as f:
                data = json.load(f)

            self.logger.info(f"ğŸ“– JSONãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(data)}ä»¶")
            return data

        except Exception as e:
            self.logger.error(f"âŒ JSONãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"Failed to load JSON data: {str(e)}")

    def _create_backup(self, data: dict[str, Any]) -> None:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

        Args:
            data: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ‡ãƒ¼ã‚¿
        """
        try:
            # æ—¢å­˜ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Œã°ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§ä¿å­˜
            if self.backup_file_path.exists():
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                archived_backup = self.backup_file_path.parent / f"effort_reports_backup_{timestamp}.json"
                self.backup_file_path.rename(archived_backup)
                self.logger.info(f"æ—¢å­˜ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å±¥æ­´ä¿å­˜: {archived_backup}")

            # æ–°ã—ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            with open(self.backup_file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            self.logger.info(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {self.backup_file_path}")

        except Exception as e:
            self.logger.error(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"Failed to create backup: {str(e)}")

    async def _migrate_data(self, json_data: dict[str, Any]) -> dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ç§»è¡Œå®Ÿè¡Œ

        Args:
            json_data: JSONãƒ‡ãƒ¼ã‚¿

        Returns:
            dict[str, Any]: ç§»è¡Œçµ±è¨ˆ
        """
        migrated_count = 0
        failed_count = 0
        errors = []

        self.logger.info(f"ğŸ“Š ç§»è¡Œå¯¾è±¡: {len(json_data)}ä»¶ã®åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆ")

        for report_id, report_data in json_data.items():
            try:
                # EffortReportRecordã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä½œæˆ
                effort_report = self._json_to_effort_report(report_id, report_data)

                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ï¼ˆé‡è¤‡ç™»éŒ²é˜²æ­¢ï¼‰
                existing_report = await self.effort_repository.get_by_id(report_id)
                if existing_report:
                    self.logger.warning(f"âš ï¸ æ—¢å­˜åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—: report_id={report_id}")
                    continue

                # SQLiteã«ä¿å­˜
                await self.effort_repository.create(effort_report)
                migrated_count += 1

                self.logger.debug(f"âœ… åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆç§»è¡ŒæˆåŠŸ: report_id={report_id}")

            except Exception as e:
                failed_count += 1
                error_msg = f"report_id={report_id}, error={str(e)}"
                errors.append(error_msg)
                self.logger.error(f"âŒ åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆç§»è¡Œå¤±æ•—: {error_msg}")

        return {
            "success": failed_count == 0,
            "migrated_count": migrated_count,
            "failed_count": failed_count,
            "errors": errors,
            "message": f"åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆç§»è¡Œå®Œäº†: æˆåŠŸ{migrated_count}ä»¶, å¤±æ•—{failed_count}ä»¶",
        }

    def _json_to_effort_report(self, report_id: str, report_data: dict[str, Any]) -> EffortReportRecord:
        """JSONãƒ‡ãƒ¼ã‚¿ã‚’EffortReportRecordã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¤‰æ›

        Args:
            report_id: ãƒ¬ãƒãƒ¼ãƒˆID
            report_data: åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆJSONãƒ‡ãƒ¼ã‚¿

        Returns:
            EffortReportRecord: åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£
        """
        try:
            return EffortReportRecord(
                report_id=report_data.get("id", report_id),
                user_id=report_data.get("user_id", ""),
                period_days=report_data.get("period_days", 7),
                effort_count=report_data.get("effort_count", 0),
                score=report_data.get("score", 0.0),
                highlights=report_data.get("highlights", []),
                categories=report_data.get("categories", {}),
                summary=report_data.get("summary", ""),
                achievements=report_data.get("achievements", []),
                created_at=report_data.get("created_at"),
                updated_at=report_data.get("updated_at"),
            )

        except Exception as e:
            self.logger.error(f"âŒ EffortReportRecordå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"Failed to convert JSON to EffortReportRecord: {str(e)}")

    async def _verify_migration(self, expected_count: int) -> None:
        """ç§»è¡Œçµæœæ¤œè¨¼

        Args:
            expected_count: æœŸå¾…ã•ã‚Œã‚‹ç§»è¡Œä»¶æ•°
        """
        try:
            # SQLiteã‹ã‚‰å…¨åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—
            actual_count = await self.effort_repository.count_reports()

            self.logger.info(f"ğŸ” ç§»è¡Œæ¤œè¨¼: æœŸå¾…ä»¶æ•°={expected_count}, å®Ÿéš›ä»¶æ•°={actual_count}")

            if actual_count < expected_count:
                raise Exception(f"Migration verification failed: expected {expected_count}, got {actual_count}")

            self.logger.info("âœ… ç§»è¡Œæ¤œè¨¼æˆåŠŸ: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª")

        except Exception as e:
            self.logger.error(f"âŒ ç§»è¡Œæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            raise Exception(f"Failed to verify migration: {str(e)}")

    async def rollback_migration(self) -> dict[str, Any]:
        """ç§»è¡Œã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆSQLiteãƒ‡ãƒ¼ã‚¿å‰Šé™¤ + JSONãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒï¼‰

        Returns:
            dict[str, Any]: ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœ
        """
        try:
            self.logger.info("ğŸ”„ åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ç§»è¡Œãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯é–‹å§‹")

            # SQLiteã‹ã‚‰å…¨åŠªåŠ›ãƒ¬ãƒãƒ¼ãƒˆã‚’å‰Šé™¤
            deleted_count = 0
            reports = await self.effort_repository.get_all_reports(limit=1000)
            for report in reports:
                success = await self.effort_repository.delete(report.report_id)
                if success:
                    deleted_count += 1

            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰JSONãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒ
            if self.backup_file_path.exists():
                self.backup_file_path.rename(self.json_file_path)
                self.logger.info(f"ğŸ“„ JSONãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒ: {self.json_file_path}")

            self.logger.info(f"âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†: {deleted_count}ä»¶å‰Šé™¤")
            return {
                "success": True,
                "deleted_count": deleted_count,
                "message": "ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†",
            }

        except Exception as e:
            self.logger.error(f"âŒ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "error": str(e)}

    async def get_migration_status(self) -> dict[str, Any]:
        """ç§»è¡ŒçŠ¶æ…‹å–å¾—

        Returns:
            dict[str, Any]: ç§»è¡ŒçŠ¶æ…‹æƒ…å ±
        """
        try:
            json_exists = self.json_file_path.exists()
            backup_exists = self.backup_file_path.exists()

            # SQLiteãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯0ã¨ã—ã¦æ‰±ã†
            sqlite_count = 0
            try:
                sqlite_count = await self.effort_repository.count_reports()
            except Exception:
                # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯0ã¨ã—ã¦ç¶™ç¶š
                sqlite_count = 0

            json_count = 0
            if json_exists:
                json_data = self._load_json_data()
                json_count = len(json_data) if json_data else 0

            return {
                "json_file_exists": json_exists,
                "json_record_count": json_count,
                "backup_file_exists": backup_exists,
                "sqlite_record_count": sqlite_count,
                "migration_needed": json_exists and sqlite_count == 0,
            }

        except Exception as e:
            self.logger.error(f"âŒ ç§»è¡ŒçŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
